#!/usr/bin/env python
import subprocess, os, getpass, time, threading

runningIDs = []
do_poll    = True

def poll(squeueCommand):
  # fetch the IDs of running jobs
  global runningIDs
  global do_poll
  while do_poll:
    squeueProcess = subprocess.Popen(
      squeueCommand,
      stdout = subprocess.PIPE,
      stderr = subprocess.PIPE,
      shell  = True)
    squeueStdout, squeueStderr = squeueProcess.communicate()
    runningIDs = squeueStdout.rstrip('\n').split('\n')
    time.sleep(2)

if __name__ == '__main__':

  # define the status codes
  STATUS_NOT_SUBMITTED = 0
  STATUS_RUNNING       = 1
  STATUS_FINISHED      = 2
  STATUS_FAILED        = 3

  # create a list of targets and necessary meta-information associated w/ each job
  jobs = { {% for targetFile, bashScript, logFile in zippedInfo %}
    '{{ targetFile }}' : {
      'logFile'    : '{{ logFile }}',
      'bashScript' : '{{ bashScript }}',
      'ID'         : -1,
      'status'     : STATUS_NOT_SUBMITTED,
      'retries'    : 0,
    },{% endfor %}
  }

  # update the queue priority if needed
  priority = '{{ priority }}'
  priority_env = os.environ.get('SBATCH_PRIORITY')
  if priority_env:
    priority = priority_env
  if not priority:
    priority = "main"

  # update the maximum number of running jobs if needed
  limit = {{ limit }}
  limit_env = os.environ.get('SBATCH_LIMIT')
  if limit_env:
    try:
      limit = int(limit_env)
    except ValueError:
      pass

  sbatchComment = '{{ sbatchComment }}'
  if sbatchComment:
    squeueCommand = "squeue -u {user} -o '%i %36k' | tail -n+2 | grep {comment}".format(
      user    = getpass.getuser(),
      comment = sbatchComment,
    )
  else:
    squeueCommand = "squeue -u {user} -o '%i' | tail -n+2".format(user = getpass.getuser())
  squeueCommand += " | awk '{print $1}'"

  poll_thread = threading.Thread(target = poll, args = (squeueCommand,))
  poll_thread.setDaemon(True)
  poll_thread.start()

  # let's loop over the entries first to see whether some files have already been finished
  # the problem we want to avoid here is that if make command is cancelled or it failed
  # for whatever reason (e.g. the cluster is back to operating normally), and we want to
  # run it again, the make command discovers some missing files and winds this script up
  # however, if we don't check for already finished targets, the jobs will be submitted
  # regardless of the completion of targets
  # in other words, all the jobs will be submitted even though we want to recover only
  # a fraction of them
  for target, entry in jobs.iteritems():
    if os.path.exists(target):
      entry['status'] = STATUS_FINISHED

  while True:
    #update status here
    for target, entry in jobs.iteritems():
      if entry['status'] == STATUS_RUNNING and entry['ID'] not in runningIDs:
        if os.path.exists(target):
          entry['status'] = STATUS_FINISHED
        else:
          if entry['retries'] > {{ maxRetries }}:
            # if the number of resubmission exceeds certain threshold, mark it as failed
            entry['status'] = STATUS_FAILED
          else:
            # otherwise resubmit the job
            entry['status'] = STATUS_NOT_SUBMITTED

    # check if all jobs have been finished
    if all([jobs[t]['status'] in (STATUS_FINISHED, STATUS_FAILED) for t in jobs]):
      break

    # submit new jobs if needed
    for target, entry in jobs.iteritems():

      # check if the number of running jobs exceeds the limit
      nof_running = len(runningIDs) if sbatchComment else len([jobst[t]['status'] == STATUS_RUNNING])
      if nof_running >= limit:
        break

      if entry['status'] == STATUS_NOT_SUBMITTED:
        # submit the job
        submitJobProcess = subprocess.Popen(
          'sbatch --partition={priority} --output={logFile} --comment="{comment}" {bashScript}'.format(
            priority   = priority,
            logFile    = entry['logFile'],
            bashScript = entry['bashScript'],
            comment    = sbatchComment,
          ),
          stdout = subprocess.PIPE,
          stderr = subprocess.PIPE,
          shell  = True
        )
        submitStdout, submitStderr = submitJobProcess.communicate()
        if submitStderr:
          raise ValueError("sbatch error: {reason}".format(reason = submitStderr))
        entry['ID']       = submitStdout.rstrip('\n').split()[-1]
        entry['status']   = STATUS_RUNNING
        entry['retries'] += 1

    # wait a little
    time.sleep(30)

  do_poll = False
  poll_thread.join()


